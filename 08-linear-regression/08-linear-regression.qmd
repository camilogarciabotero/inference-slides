---
title: Correlation & Lineal regression
subtitle: "https://bit.ly/3IlpxQ5"
author:
  - name: Camilo G.
    email: ca.garcia2@uniandes.edu.co

  - name: "Kevin J."
    email: ks.jaramillo1905@uniandes.edu.co

  - name: "Victor A."
    email: v.nascimento@uniandes.edu.co
format:
  revealjs:
    footer: |
      BIOL2205 - IeI - Universidad de los Andes
    standalone: true
    preview-links: auto
    center: true
    slide-number: true
    fig-align: center
    code-line-numbers: false
    overview: true
    code-link: true
    code-annotations: hover
    highlight-style: ayu
    df-print: paged
    scrollable: true
    fig-height: 5
    fig-width: 5
    fig-dpi: 350
    theme: ../theme.scss
    bibliography: ../references.bib
---

```{r}
#| label: theme-set
#| eval: true
library(tidyverse)
library(palmerpenguins)
library(latex2exp)
library(performance)
library(statsExpressions)
library(ggsignif)
library(ggpmisc)

simple_theme <- theme_bw() +
    theme(
        plot.background = element_rect(fill = "#FDF6E3"),
        panel.background = element_rect(fill = "#FDF6E3"),
        legend.background = element_rect(fill = "#FDF6E3"),
        legend.position = "bottom",
        axis.title = element_text(size = 14)
    )

theme_set(simple_theme)
```

# Correlation

***

Correlation is a measurement of the extent of which two variables relate to each other. Its coefficient tells the direction and strength of this relationship.

***

![](figs/culmen_depth.png)

***

```{r}
#| label: correlation
#| fig-align: center
#| echo: true
#| eval: true
#| code-fold: true
ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +
    geom_point(size = 2, alpha = 0.6) +
    labs(
        title = "Penguin bill dimensions (omit species)",
        x = "Bill length (mm)",
        y = "Bill depth (mm)"
    ) +
    geom_smooth(method = "lm", se = FALSE, color = "gray50")
```

***

### How much are those variables correlated?

***

## The *Pearson* correlation coefficient

The *Pearson* correlation coefficient stablish the degree of correlation between two random variables:

$$
\rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_{X}\sigma_{Y}}
$$

***

In R:

```{r}
#| label: pearson
#| fig-align: center
#| echo: true
#| eval: true
#| output-location: fragment
cor.test(penguins$bill_length_mm, penguins$bill_depth_mm, method = "pearson")
```

***

The *Pearson* Correlation assumptions:

- $X$ and $Y$ display a linear tendency. 
- $X$ and $Y$ display a normal distribution.


## The *Spearman* correlation coefficient

$$
\rho_{X,Y} = \frac{Cov(R(X),R(Y))}{\sigma_{R(X)}\sigma_{R(Y)}}
$$

The $R$ in the equation is a ranking of the the two random variables.

***

In R:

```{r}
#| label: spearman
#| fig-align: center
#| echo: true
#| eval: true
#| output-location: fragment
cor.test(penguins$bill_length_mm, penguins$bill_depth_mm, method = "spearman")
```

# Linear regression

***

Before dive into the *linear regression* model creation and the hypothesis testing. Let's talk about two important principles for sampling in the experimental design you are performing.

***

### 1. Capture full ranges of response

::: columns

::: {.column width="50%"}
![](figs/uniform-01.png)
:::

::: {.column width="50%"}
![](figs/uniform-02.png)
:::

:::

***

### 2. Sample range uniformly

::: columns

::: {.column width="50%"}
![](figs/responses-01.png)
:::

::: {.column width="50%"}
![](figs/responses-02.png)
:::

:::

## Linear regression model

***

The linear regression model is a statistical model that allows us to predict the value of a dependent variable $Y$ based on the value of an independent variable $X$.

***

![](figs/lm-model.png){fig-align="center"}

***

![](figs/null-hypothesis.png){fig-align="center"}

***

![](figs/alternative-hypothesis.png){fig-align="center"}


## Applying the linear regression model

***

![](figs/regression-01.png){fig-align="center"}

*** 

![](figs/regression-02.png){fig-align="center"}

***

![](figs/regression-03.png){fig-align="center"}

## Finding the best fit

***

![](figs/determination-coeff.png){fig-align="center" width="70"}

## Testing the hypothesis in linear regression

***

How do we test if the **SSreg** ($𝐻_{𝐴}$) explain the data trend?

. . . 

or, in other words...

. . .

How do we test if the $𝐻_{0}$ do not explain the data trend?

***

## 1. Specifying the statistical test

***

$$
F_{(df,n)} = \frac{SS_{reg}}{\frac{RSS}{(n − 2)}}
$$


***

![](figs/fisher.png){fig-align="center"}

***

## 2. Calculating the tail probability in T-distribution

***

$$
X \sim F_{(1,n)} \Rightarrow X \sim T_{n}
$$

## Let's do it in R


```{r}
#| label: lm-01
#| fig-align: center
#| echo: true
#| eval: true
#| output-location: column-fragment
#| fig-width: 7
ggplot(penguins, 
  aes(
      x = flipper_length_mm, 
      y = body_mass_g)
      ) +
    geom_point(size = 2, alpha = 0.6) +
    labs(
        title = "Penguin bill dimensions",
        x = "flipper length (mm)",
        y = "Body mass (g)"
    ) +
    geom_smooth(method = "lm")
```

***

Let's investigate the model:


```{r}
#| label: lm-02
#| fig-align: center
#| echo: true
#| output-location: fragment
model  <- lm(body_mass_g ~ flipper_length_mm, data = penguins)
```


```{r}
model
```

***

We can use the package `report` to get a nice summary of the model:

```{r}
#| label: lm-03
#| fig-align: center
#| echo: true
#| output-location: fragment
report::report(model)
```

***

We can also include the complete model in the plot with the `ggpmisc`:

```{r}
#| label: lm-04
#| fig-align: center
#| echo: true
#| eval: true
#| output-location: column-fragment
#| fig-width: 7
ggplot(penguins, 
  aes(
      x = flipper_length_mm, 
      y = body_mass_g)
      ) +
    geom_point(size = 2, alpha = 0.6) +
    labs(
        title = "Penguin bill dimensions",
        x = "flipper length (mm)",
        y = "Body mass (g)"
    ) +
    geom_smooth(method = "lm") +
    stat_poly_eq(use_label(
      c("eq", "R2", "F", "p.value"),
    ))
```

## Testing the regression assumtions

***

1. Linearity: function behaves linearly outside the range of the data.

```{r}
#| label: linearity
#| fig-align: center
#| echo: true
#| eval: true
performance::check_model(model, check = "linearity")
```

***

2. Normality: residuals are normally distributed.

```{r}
#| label: normality
#| fig-align: center
#| echo: true
#| eval: true
performance::check_normality(model)
plot(check_normality(model), type = "qq")
```

***

3. Variance homogeneity: residuals have constant variance.

```{r}
#| label: heteroskedasticity
#| fig-align: center
#| echo: true
#| eval: true
check_heteroskedasticity(model)
plot(check_heteroskedasticity(model))
```
